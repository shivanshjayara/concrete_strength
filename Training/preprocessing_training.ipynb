{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loving-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.impute import KNNImputer\n",
    "from Training_log_module.training_log import train_logging\n",
    "import pickle\n",
    "\n",
    "class preprocessing_training_class:\n",
    "    def __init__(self):\n",
    "        self.file_name = '../html_heroku_deployment/training_data.csv' \n",
    "        self.df = pd.read_csv(self.file_name)\n",
    "        \n",
    "        self.log_filename = 'training_log.txt'\n",
    "        self.log_obj = train_logging(self.log_filename)\n",
    "        \n",
    "        self.log_obj.true_log('Preprocessing starte from here************')\n",
    "        \n",
    "    def check_std_zero(self):\n",
    "        '''Checking if there is any feature having standard deviation=0\n",
    "            If yes then we will going to remove that because all the point in that features will be equal to mean and \n",
    "            it will cause issue in the calculation\n",
    "            The dispersion of the data points from the mean will be 0 because actual value equals to mean, \n",
    "            it means data is not deviates from mean.\n",
    "            Values of that column are constant, means whether the strength is good or bad, that values does not changing.\n",
    "            It means that it has no impact on the target values. So we have to delete that column.\n",
    "            Hence it is ot necessary for model training as it is not helping in predicting.\n",
    "            Then we are putting those feature in separate csv file\n",
    "        '''\n",
    "        \n",
    "        self.log_obj.true_log(f'''Defining a fuction which will check if any column has a standard deviation zero or not.\n",
    "        If it is zero then that column will be removed. The dispersion of the data points from the mean will be 0 because\n",
    "        actual value equals to mean, it means data is not deviates from mean. Values of that column are constant,\n",
    "        means whether the strength is good or bad, that values does not changing. It means that it has no impact on the \n",
    "        target values. So we have to delete that column.''')\n",
    "        \n",
    "        self.df2=self.df.copy()\n",
    "        self.std_zero = {}\n",
    "        list_drop_col=[]\n",
    "        \n",
    "        self.log_obj.true_log('Checking the column one by one for standard deviation zero')\n",
    "        for i in list(self.df.columns):\n",
    "            if self.df2[i].std() == 0: # Chceking for column having zero standard deviation\n",
    "                self.std_zero[i] = 0 # Filling the diction with key=column name & value=standard deviation\n",
    "                list_drop_col.append(i)\n",
    "        \n",
    "        self.df2.drop(columns = list_drop_col, inplace = True) # Dropping those columns having std zero\n",
    "\n",
    "        self.log_obj.true_log('Columns having zero standard deviation are dropped.')\n",
    "        \n",
    "#         self.std_zero_df = pd.DataFrame([self.std_zero])\n",
    "#         self.std_zero_df.to_csv('std_zero_data.csv', index = False, header = True)\n",
    "        \n",
    "#         self.log_obj.true_log('The columns having zero standard deviation is exported to new csv file')       \n",
    "        \n",
    "        return self.df2\n",
    "\n",
    "        \n",
    "    def replacing_to_nullvalues(self):\n",
    "        self.log_obj.true_log('Defining a function that will Replace all the 0 (zero) in every column with null value')\n",
    "        df = self.check_std_zero()\n",
    "        null_dic = {}\n",
    "            \n",
    "        for feature in list(df.columns):\n",
    "            self.log_obj.true_log(f'Checking in {feature} column for 0 (zero)')\n",
    "            df[feature] = df[feature].replace({0.0:None})\n",
    "                \n",
    "#             if df[feature].isnull().sum() > 0:\n",
    "#                 null_dic[feature] = df[feature].isnull().sum()\n",
    "\n",
    "#         null_df = pd.DataFrame([null_dic], index = ['No. of missing_values']).transpose().reset_index().rename(columns = {'index':'Features'})\n",
    "        \n",
    "#         null_df.to_csv('missing_values_data.csv', index = False, header=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "        \n",
    "    def filling_null_values(self):\n",
    "        '''In this we will be fill all the null values with the mean.\n",
    "           For filling out the mean we will be using KNN imputer, where Nearest neighbor will 3.\n",
    "           This is because, the value which is missing is somehow around its neighbours.\n",
    "           So we will take the mean of its 3 neighbors and fill the mising values with those\n",
    "        '''\n",
    "        df=self.replacing_to_nullvalues()\n",
    "        self.log_obj.true_log('Defining a fuction which will fill all the null values with mean by using KNNImputer ******')\n",
    "        \n",
    "        try:\n",
    "            self.log_obj.true_log('Creating an object for KNNImputer and we are taking 3 nearest neighbors')\n",
    "            imputer = KNNImputer(n_neighbors = 3)\n",
    "            self.log_obj.true_log('Fitting the data')\n",
    "            impute_data = imputer.fit_transform(df)\n",
    "            self.log_obj.true_log('''Each sample's missing values are imputed using the mean value from\n",
    "            3 nearest neighbors found in the data set''')\n",
    "            self.log_obj.true_log('Creating a separate dataframe that will store the updated data set with mean values in place of null values')\n",
    "            self.imputed_df = pd.DataFrame(impute_data,columns = df.columns)\n",
    "            self.log_obj.true_log('Rounding the values such that after decimal there is only two digits present')\n",
    "            for feature in self.imputed_df.columns:\n",
    "                self.imputed_df[feature]=self.imputed_df[feature].apply(lambda a: round(a,2))\n",
    "            self.log_obj.true_log('Rounding complete')\n",
    "#             self.log_obj.true_log('Saving this dataframe in the final training training file fiolder')\n",
    "#             self.imputed_df.to_csv('training_data_withoutnull.csv',index=False,header=True)\n",
    "            return self.imputed_df\n",
    "        except Exception as e:\n",
    "            self.log_obj.error_log(f'Unable to fill missing values due to this error: {str(e)}')\n",
    "                    \n",
    "        \n",
    "    def outliers_removal(self):\n",
    "        self.log_obj.true_log('Defining a function that will remove the outliers from the dataset ******')\n",
    "        dataframe = self.filling_null_values()\n",
    "        \n",
    "        try:\n",
    "            self.log_obj.true_log('For removing the outlier, quantile function is used from Numpy library')\n",
    "            \n",
    "            for i in list(dataframe.columns):\n",
    "                self.log_obj.true_log(f'For {i} column :')\n",
    "                q1 = dataframe[i].quantile(0.25)\n",
    "                q3 = dataframe[i].quantile(0.75)\n",
    "                self.log_obj.true_log(f'First qunatile position is: {q1}')\n",
    "                self.log_obj.true_log(f'Third qunatile position is: {q3}')\n",
    "                \n",
    "                iqr = q3-q1\n",
    "                self.log_obj.true_log(f'Inter Quantile Range is {iqr}')\n",
    "                lower = q1-1.5*iqr\n",
    "                upper = q3+1.5*iqr\n",
    "                self.log_obj.true_log(f'Lower range value is: {lower}')\n",
    "                self.log_obj.true_log(f'Upper range value is: {upper}')\n",
    "                \n",
    "                dataframe = dataframe[(dataframe[i] > lower) & (dataframe[i] < upper)]\n",
    "            self.log_obj.true_log('New dataset after removing the outliers is updated')\n",
    "            \n",
    "            return dataframe\n",
    "        except Exception as e:\n",
    "            self.log_obj.error_log(f'Unable to remove the out liers because of this error: {str(e)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
